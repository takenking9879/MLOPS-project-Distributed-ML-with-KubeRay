{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6de38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_parquet('processed/train.snappy.parquet')\n",
    "df_val = pd.read_parquet('processed/val.snappy.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d3c047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[local-xgboost] cpu_count=24 | OMP_NUM_THREADS=24\n",
      "[local-xgboost] num_class=6\n",
      "[0]\tvalidation-mlogloss:0.75514\tvalidation-merror:0.00833\n",
      "[10]\tvalidation-mlogloss:0.04549\tvalidation-merror:0.00400\n",
      "[20]\tvalidation-mlogloss:0.01370\tvalidation-merror:0.00433\n",
      "[30]\tvalidation-mlogloss:0.01207\tvalidation-merror:0.00433\n",
      "[40]\tvalidation-mlogloss:0.01193\tvalidation-merror:0.00400\n",
      "[50]\tvalidation-mlogloss:0.01185\tvalidation-merror:0.00400\n",
      "[60]\tvalidation-mlogloss:0.01187\tvalidation-merror:0.00400\n",
      "[70]\tvalidation-mlogloss:0.01194\tvalidation-merror:0.00400\n",
      "[80]\tvalidation-mlogloss:0.01197\tvalidation-merror:0.00367\n",
      "[90]\tvalidation-mlogloss:0.01202\tvalidation-merror:0.00367\n",
      "[99]\tvalidation-mlogloss:0.01213\tvalidation-merror:0.00367\n",
      "[local-xgboost] train_time_sec=14.74\n",
      "[local-xgboost] val_accuracy=0.9963 | val_merror=0.0037\n"
     ]
    }
   ],
   "source": [
    "# XGBoost local (sin Ray) usando el mismo batch: df_train/df_val ya cargados arriba\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception as e:\n",
    "    raise ImportError(\"No se pudo importar xgboost. Instala con: pip install xgboost\") from e\n",
    "\n",
    "TARGET = \"attack\"\n",
    "assert TARGET in df_train.columns, f\"No existe columna target '{TARGET}' en df_train. Columnas: {list(df_train.columns)[:30]}...\"\n",
    "assert TARGET in df_val.columns, f\"No existe columna target '{TARGET}' en df_val. Columnas: {list(df_val.columns)[:30]}...\"\n",
    "\n",
    "# Asegura uso de todos los cores disponibles (puedes limitarlo con OMP_NUM_THREADS si quieres)\n",
    "cpu_count = os.cpu_count() or 1\n",
    "for var in (\n",
    "    \"OMP_NUM_THREADS\",\n",
    "    \"MKL_NUM_THREADS\",\n",
    "    \"OPENBLAS_NUM_THREADS\",\n",
    "    \"NUMEXPR_NUM_THREADS\",\n",
    "    \"VECLIB_MAXIMUM_THREADS\",\n",
    "    \"XGBOOST_NUM_THREADS\",\n",
    "    \"XGB_NUM_THREADS\",\n",
    "    \"RAYON_NUM_THREADS\",\n",
    "    ):\n",
    "    os.environ[var] = str(cpu_count)\n",
    "\n",
    "print(f\"[local-xgboost] cpu_count={cpu_count} | OMP_NUM_THREADS={os.environ.get('OMP_NUM_THREADS')}\")\n",
    "\n",
    "# Replica de params (tomados de k3s/kuberay/schemas/xgboost_params.py) pero sin importar Ray\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"eval_metric\": [\"mlogloss\", \"merror\"],\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"verbosity\": 1,\n",
    "    \"eta\": 0.3,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"subsample\": 1.0,\n",
    "    \"lambda\": 1.0,\n",
    "    \"alpha\": 0.0,\n",
    "    # threading\n",
    "    \"nthread\": cpu_count,\n",
    "}\n",
    "\n",
    "# Inferir num_class desde el batch actual (igual que el módulo de Ray: params['num_class']=num_classes)\n",
    "num_class = int(pd.concat([df_train[TARGET], df_val[TARGET]], axis=0).nunique())\n",
    "params[\"num_class\"] = num_class\n",
    "print(f\"[local-xgboost] num_class={num_class}\")\n",
    "\n",
    "# DMatrix (usa el batch actual tal cual)\n",
    "X_train = df_train.drop(columns=[TARGET])\n",
    "y_train = df_train[TARGET].astype(\"int64\")\n",
    "X_val = df_val.drop(columns=[TARGET])\n",
    "y_val = df_val[TARGET].astype(\"int64\")\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, nthread=cpu_count)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, nthread=cpu_count)\n",
    "\n",
    "num_boost_round = 100  # igual al default del esquema\n",
    "t0 = time.perf_counter()\n",
    "booster = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dval, \"validation\")],\n",
    "    verbose_eval=10,\n",
    ")\n",
    "dt = time.perf_counter() - t0\n",
    "print(f\"[local-xgboost] train_time_sec={dt:.2f}\")\n",
    "\n",
    "# Métrica rápida en val (merror/accuracy)\n",
    "probs = booster.predict(dval)\n",
    "if probs.ndim == 1:\n",
    "    y_pred = (probs > 0.5).astype(\"int64\")\n",
    "else:\n",
    "    y_pred = probs.argmax(axis=1).astype(\"int64\")\n",
    "y_true = y_val.to_numpy()\n",
    "acc = float((y_pred == y_true).mean())\n",
    "merror = 1.0 - acc\n",
    "print(f\"[local-xgboost] val_accuracy={acc:.4f} | val_merror={merror:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-platform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
