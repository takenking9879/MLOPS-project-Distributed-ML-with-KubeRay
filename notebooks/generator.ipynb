{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e06b50b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating datasets...\n",
      "Saved parquet to out/train.parquet\n",
      "Saved parquet to out/val_normal.parquet\n",
      "Saved parquet to out/val_data.parquet\n",
      "Saved parquet to out/val_concept.parquet\n",
      "Preprocessing train (Pandas)...\n",
      "Preprocessing val_normal (Pandas)...\n",
      "\n",
      "=== EXP: train on normal, eval on normal/data/concept ===\n",
      "Trained with GPU.\n",
      "\n",
      "--- val_normal --- Accuracy: 0.9960\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9979    0.9982    0.9980      2801\n",
      "         DoS     1.0000    1.0000    1.0000        68\n",
      "       Probe     0.8387    0.8667    0.8525        30\n",
      "         R2L     1.0000    1.0000    1.0000        57\n",
      "         U2R     1.0000    0.8966    0.9455        29\n",
      "        Worm     0.9375    1.0000    0.9677        15\n",
      "\n",
      "    accuracy                         0.9960      3000\n",
      "   macro avg     0.9623    0.9602    0.9606      3000\n",
      "weighted avg     0.9961    0.9960    0.9960      3000\n",
      "\n",
      "\n",
      "--- val_data_drift --- Accuracy: 0.8757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9944    0.8754    0.9311      2833\n",
      "         DoS     0.7895    0.9677    0.8696        62\n",
      "       Probe     1.0000    0.6000    0.7500        25\n",
      "         R2L     0.1293    1.0000    0.2291        41\n",
      "         U2R     0.1667    0.6316    0.2637        19\n",
      "        Worm     0.7308    0.9500    0.8261        20\n",
      "\n",
      "    accuracy                         0.8757      3000\n",
      "   macro avg     0.6351    0.8375    0.6449      3000\n",
      "weighted avg     0.9714    0.8757    0.9138      3000\n",
      "\n",
      "\n",
      "--- val_concept_drift --- Accuracy: 0.1357\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.1365    0.9343    0.2381       411\n",
      "         DoS     0.0000    0.0000    0.0000       433\n",
      "       Probe     0.7931    0.0369    0.0706       623\n",
      "         R2L     0.0000    0.0000    0.0000      1271\n",
      "         U2R     0.0000    0.0000    0.0000        25\n",
      "        Worm     0.0000    0.0000    0.0000       237\n",
      "\n",
      "    accuracy                         0.1357      3000\n",
      "   macro avg     0.1549    0.1619    0.0514      3000\n",
      "weighted avg     0.1834    0.1357    0.0473      3000\n",
      "\n",
      "\n",
      "=== EXP: retrain on concept (using df_concept_train_proc) ===\n",
      "Trained with GPU.\n",
      "\n",
      "--- concept_val (after retrain) --- Accuracy: 0.7520\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.7354    0.9197    0.8173       411\n",
      "         DoS     0.7621    0.9469    0.8445       433\n",
      "       Probe     0.3978    0.0594    0.1034       623\n",
      "         R2L     0.7731    0.9811    0.8648      1271\n",
      "         U2R     0.8750    0.8400    0.8571        25\n",
      "        Worm     0.7477    0.6878    0.7165       237\n",
      "\n",
      "    accuracy                         0.7520      3000\n",
      "   macro avg     0.7152    0.7391    0.7006      3000\n",
      "weighted avg     0.6873    0.7520    0.6854      3000\n",
      "\n",
      "\n",
      "Sample processed train head:\n",
      "   src_port  dst_port  protocol  packet_count  conn_state  bytes_transferred  \\\n",
      "0     48364     35671         1           218           0      491361.431556   \n",
      "1     18818     62148         1           373           0      430263.657678   \n",
      "2     20905     32564         1            31           0      344261.424094   \n",
      "3     21780     46160         2           368           0      469436.194252   \n",
      "4     41186     36487         1            47           0      361433.272994   \n",
      "5     30440        22         2          1285           0       96038.041518   \n",
      "\n",
      "            timestamp  attack  timestamp_epoch  bytes_log  ...  \\\n",
      "0 2026-01-12 18:00:32       0       1768240832  13.104937  ...   \n",
      "1 2026-01-12 18:01:31       0       1768240891  12.972156  ...   \n",
      "2 2026-01-12 18:02:21       0       1768240941  12.749160  ...   \n",
      "3 2026-01-12 18:03:40       0       1768241020  13.059290  ...   \n",
      "4 2026-01-12 18:04:45       0       1768241085  12.797835  ...   \n",
      "5 2026-01-12 18:05:00       1       1768241100  11.472510  ...   \n",
      "\n",
      "   bytes_per_packet_log_norm  prev_bytes_mean_3_norm  prev_packet_mean_3_norm  \\\n",
      "0                   0.432787                     0.0                      0.0   \n",
      "1                  -0.016094                     0.0                      0.0   \n",
      "2                   1.486635                     0.0                      0.0   \n",
      "3                   0.051493                     0.0                      0.0   \n",
      "4                   1.246743                     0.0                      0.0   \n",
      "5                  -1.846644                     0.0                      0.0   \n",
      "\n",
      "  prev_event_count_3_norm  session_bytes_max_norm  session_bytes_min_norm  \\\n",
      "0                     0.0                0.824719                0.824719   \n",
      "1                     0.0                0.714875                0.714875   \n",
      "2                     0.0                0.530399                0.530399   \n",
      "3                     0.0                0.786957                0.786957   \n",
      "4                     0.0                0.570667                0.570667   \n",
      "5                     0.0               -0.525721               -0.525721   \n",
      "\n",
      "   session_packet_mean_norm  protocol_norm  conn_state_norm  \\\n",
      "0                  0.338529      -0.891064         -0.09259   \n",
      "1                  0.868317      -0.891064         -0.09259   \n",
      "2                 -1.565418      -0.891064         -0.09259   \n",
      "3                  0.854994       1.027266         -0.09259   \n",
      "4                 -1.164040      -0.891064         -0.09259   \n",
      "5                  2.090903       1.027266         -0.09259   \n",
      "\n",
      "   timestamp_epoch_norm  \n",
      "0             -1.731123  \n",
      "1             -1.729420  \n",
      "2             -1.727976  \n",
      "3             -1.725696  \n",
      "4             -1.723819  \n",
      "5             -1.723386  \n",
      "\n",
      "[6 rows x 37 columns]\n",
      "\n",
      "Feature columns used: ['src_port_norm', 'dst_port_norm', 'packet_count_norm', 'bytes_transferred_norm', 'bytes_log_norm', 'packet_log_norm', 'bytes_per_packet_norm', 'bytes_per_packet_log_norm', 'prev_bytes_mean_3_norm', 'prev_packet_mean_3_norm', 'prev_event_count_3_norm', 'session_bytes_max_norm', 'session_bytes_min_norm', 'session_packet_mean_norm', 'protocol_norm', 'conn_state_norm', 'timestamp_epoch_norm']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "OOP Synthetic Traffic Generator + large preprocessing (Pandas) + PySpark-equivalent pipeline\n",
    "Run as script. If pyspark available, pyspark path will be shown and can be used.\n",
    "\n",
    "REFRACTOR NOTES (Jan 2026)\n",
    "\n",
    "Goals (without changing observable behavior: schema/labels/attack meaning):\n",
    "- `produce()` is O(1), single-sample, no Python loops, no rejection/correction.\n",
    "- Batch generation is vectorized and can scale to millions of rows.\n",
    "- Clear separation:\n",
    "  - Timestamp sequencing\n",
    "  - Attack sampling\n",
    "  - Feature sampling (attack semantics + data drift)\n",
    "  - Oracle/labeling (normal vs concept drift decision)\n",
    "\n",
    "Correctness guarantees checklist (by construction):\n",
    "- Same feature schema + attack labels.\n",
    "- Monotonic, block-based timestamps.\n",
    "- Supports `trend in {'normal','data_drift','concept_drift'}`.\n",
    "- Reproducible via the injected RNG (no global randomness).\n",
    "- No rejection sampling and no \"call oracle to fix samples\".\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import warnings, json, os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# reproducibilidad\n",
    "SEED = 42\n",
    "RNG = np.random.RandomState(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# -------------------------\n",
    "# Config global / schema\n",
    "# -------------------------\n",
    "SCHEMA = {\n",
    "    'src_port': {'type': 'int', 'range': (1024, 65535)},\n",
    "    'dst_port': {'type': 'int', 'range': (1, 65535)},\n",
    "    'protocol': {'type': 'cat', 'vals': ['TCP', 'UDP', 'ICMP']},\n",
    "    'packet_count': {'type': 'int', 'range': (1, 2000)},\n",
    "    'conn_state': {'type': 'cat', 'vals': ['EST', 'SYN', 'FIN', 'RST']},\n",
    "    'bytes_transferred': {'type': 'float', 'range': (0.0, 2e6)},\n",
    "    'timestamp': {'type': 'time'}\n",
    "}\n",
    "BASE_FEATURES = list(SCHEMA.keys())\n",
    "\n",
    "NUM_CLASSES = 6\n",
    "ATTACK_LABELS = {0:'Normal',1:'DoS',2:'Probe',3:'R2L',4:'U2R',5:'Worm'}\n",
    "ATTACK_TO_ID = {v:k for k,v in ATTACK_LABELS.items()}\n",
    "ATTACK_PRIORS = {'Normal':0.942,'DoS':0.02,'Probe':0.01,'R2L':0.015,'U2R':0.008,'Worm':0.005}\n",
    "ATTACK_NAMES = list(ATTACK_PRIORS.keys())\n",
    "ATTACK_PROBS = list(ATTACK_PRIORS.values())\n",
    "\n",
    "_PROTO_VALS = np.array(SCHEMA['protocol']['vals'], dtype=object)\n",
    "_CONN_VALS = np.array(SCHEMA['conn_state']['vals'], dtype=object)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Fast categorical sampling (Alias method)\n",
    "# -------------------------\n",
    "class _AliasSampler:\n",
    "    \"\"\"O(1) discrete sampler after O(K) preprocessing.\"\"\"\n",
    "\n",
    "    def __init__(self, probs, rng: np.random.RandomState):\n",
    "        p = np.asarray(probs, dtype=np.float64)\n",
    "        if p.ndim != 1:\n",
    "            raise ValueError(\"probs must be a 1D array\")\n",
    "        if np.any(p < 0):\n",
    "            raise ValueError(\"probs must be non-negative\")\n",
    "        s = float(p.sum())\n",
    "        if not np.isfinite(s) or s <= 0:\n",
    "            raise ValueError(\"probs must sum to a positive finite value\")\n",
    "        p = p / s\n",
    "\n",
    "        self.rng = rng\n",
    "        self.K = int(p.size)\n",
    "        self.prob = np.empty(self.K, dtype=np.float64)\n",
    "        self.alias = np.empty(self.K, dtype=np.int32)\n",
    "\n",
    "        scaled = p * self.K\n",
    "        small = []\n",
    "        large = []\n",
    "        for i in range(self.K):\n",
    "            (small if scaled[i] < 1.0 else large).append(i)\n",
    "\n",
    "        while small and large:\n",
    "            sidx = small.pop()\n",
    "            lidx = large.pop()\n",
    "            self.prob[sidx] = scaled[sidx]\n",
    "            self.alias[sidx] = lidx\n",
    "            scaled[lidx] = (scaled[lidx] + scaled[sidx]) - 1.0\n",
    "            (small if scaled[lidx] < 1.0 else large).append(lidx)\n",
    "\n",
    "        for idx in large:\n",
    "            self.prob[idx] = 1.0\n",
    "            self.alias[idx] = idx\n",
    "        for idx in small:\n",
    "            self.prob[idx] = 1.0\n",
    "            self.alias[idx] = idx\n",
    "\n",
    "    def sample_one(self) -> int:\n",
    "        k = int(self.rng.randint(0, self.K))\n",
    "        return k if float(self.rng.random()) < float(self.prob[k]) else int(self.alias[k])\n",
    "\n",
    "    def sample_n(self, n: int) -> np.ndarray:\n",
    "        n = int(n)\n",
    "        k = self.rng.randint(0, self.K, size=n)\n",
    "        u = self.rng.random(size=n)\n",
    "        return np.where(u < self.prob[k], k, self.alias[k]).astype(np.int32, copy=False)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# SyntheticTrafficGenerator (refactored, same external API)\n",
    "# -------------------------\n",
    "class SyntheticTrafficGenerator:\n",
    "    \"\"\"Rule-based traffic generator with explicit drift modes.\n",
    "\n",
    "    External behavior preserved:\n",
    "    - Same schema (src_port, dst_port, protocol, packet_count, conn_state, bytes_transferred, timestamp)\n",
    "    - Same labels (0..5 with ATTACK_LABELS mapping)\n",
    "    - Same `produce()` output JSON schema\n",
    "    - Same `generate_dataset()` return shape/columns\n",
    "\n",
    "    Drift semantics:\n",
    "    - normal: baseline distributions + deterministic label = sampled attack id\n",
    "    - data_drift: feature distributions shift; label semantics unchanged\n",
    "    - concept_drift: features sampled like normal; label assigned by concept oracle (fX_concept)\n",
    "\n",
    "    Performance:\n",
    "    - `produce()` is O(1), has no loops and no rejection/correction.\n",
    "    - `generate_dataset()` is vectorized.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_ts: str = \"2026-01-12 18:00:00\",\n",
    "        epsilon_seconds: int = 60,\n",
    "        rng: np.random.RandomState = None,\n",
    "    ):\n",
    "        self.start_ts = pd.to_datetime(start_ts)\n",
    "        self.epsilon = int(epsilon_seconds)\n",
    "        self.rng = rng if rng is not None else np.random.RandomState(None)\n",
    "        self.n_step = 0\n",
    "\n",
    "        # Attack sampling is O(1) per sample (no loops in produce).\n",
    "        self._attack_sampler = _AliasSampler(ATTACK_PROBS, self.rng)\n",
    "\n",
    "        # Precompute categorical encodings for vectorized paths.\n",
    "        self._proto_to_idx = {v: i for i, v in enumerate(_PROTO_VALS.tolist())}\n",
    "        self._conn_to_idx = {v: i for i, v in enumerate(_CONN_VALS.tolist())}\n",
    "\n",
    "    # -------- Timestamp sequencing (monotonic, block-based) --------\n",
    "    def next_timestamp(self):\n",
    "        i = self.n_step\n",
    "        block_start = self.start_ts + pd.Timedelta(seconds=i * self.epsilon)\n",
    "        delta = float(self.rng.uniform(0, self.epsilon))\n",
    "        ts = block_start + pd.Timedelta(seconds=delta)\n",
    "        self.n_step += 1\n",
    "        return ts.replace(microsecond=0)\n",
    "\n",
    "    def next_timestamps(self, n: int) -> pd.DatetimeIndex:\n",
    "        n = int(n)\n",
    "        i = self.n_step + np.arange(n, dtype=np.int64)\n",
    "        base = self.start_ts.to_datetime64() + (i * self.epsilon).astype('timedelta64[s]')\n",
    "        delta = (self.rng.uniform(0, self.epsilon, size=n)).astype(np.int64)\n",
    "        ts = base + delta.astype('timedelta64[s]')\n",
    "        self.n_step += n\n",
    "        return pd.to_datetime(ts).floor('S')\n",
    "\n",
    "    def reset(self, start_ts: str = None, epsilon_seconds: int = None):\n",
    "        if start_ts is not None:\n",
    "            self.start_ts = pd.to_datetime(start_ts)\n",
    "        if epsilon_seconds is not None:\n",
    "            self.epsilon = int(epsilon_seconds)\n",
    "        self.n_step = 0\n",
    "\n",
    "    # -------- Latent structure helpers (explicit, human interpretable) --------\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def cat_to_num(val, choices):\n",
    "        idx = choices.index(val)\n",
    "        return -1 + 2 * idx / (len(choices) - 1) if len(choices) > 1 else 0.0\n",
    "\n",
    "    # -------- Oracle logic (kept compatible; used for concept drift + evaluation) --------\n",
    "    def fX_normal(self, row):\n",
    "        pc = float(row['packet_count']) / 2000.0\n",
    "        bt = float(row['bytes_transferred']) / 2e6\n",
    "        sp = float(row['src_port']) / 65535.0\n",
    "        dp = float(row['dst_port']) / 65535.0\n",
    "        proto = self.cat_to_num(row['protocol'], SCHEMA['protocol']['vals'])\n",
    "        state = self.cat_to_num(row['conn_state'], SCHEMA['conn_state']['vals'])\n",
    "        score = np.zeros(NUM_CLASSES)\n",
    "        score[1] += 3.0 * pc**2 + 1.5 * self.sigmoid(proto - 0.5) + 0.5 * (1 - sp) + 0.3 * pc * proto\n",
    "        score[2] += 1.5 * np.isin(row['dst_port'], [21, 22, 23, 80, 443]) + 2.0 * (pc * (1 - pc)) + 0.5 * dp * pc + 0.3 * dp * state\n",
    "        score[3] += 2.0 * state * (1 - bt) + 0.5 * (1 - dp) + 0.3 * bt * state + 1.0 * (1 - pc) * state\n",
    "        score[4] += 1.5 * bt**2 + 0.5 * state * sp + 0.3 * bt * pc + 0.5 * sp * (1 - dp)\n",
    "        score[5] += 2.0 * bt * pc + 0.5 * (1 * (row['protocol'] != 'ICMP')) + 0.3 * sp * dp\n",
    "        score[0] += 1.0 - abs(pc - 0.3) - abs(bt - 0.3) + 0.2 * (1 - abs(proto)) + 0.1 * (1 - abs(state))\n",
    "        score += 0.02 * self.rng.randn(NUM_CLASSES)\n",
    "        return int(np.argmax(score))\n",
    "\n",
    "    def fX_concept(self, row):\n",
    "        pc = float(row['packet_count']) / 2000.0\n",
    "        bt = float(row['bytes_transferred']) / 2e6\n",
    "        sp = float(row['src_port']) / 65535.0\n",
    "        dp = float(row['dst_port']) / 65535.0\n",
    "        proto = self.cat_to_num(row['protocol'], SCHEMA['protocol']['vals'])\n",
    "        state = self.cat_to_num(row['conn_state'], SCHEMA['conn_state']['vals'])\n",
    "        score = np.zeros(NUM_CLASSES)\n",
    "        score[1] += 4.0 * bt + 0.8 * (row['protocol'] == 'ICMP') - 0.3 * pc\n",
    "        src_mod = (row['src_port'] % 1000) / 1000.0\n",
    "        score[2] += 3.0 * (src_mod < 0.2) + 1.0 * np.isin(row['dst_port'], [21, 22, 23, 80, 443])\n",
    "        score[3] += 2.0 * (row['protocol'] == 'ICMP') + 1.0 * (0.05 < bt < 0.2)\n",
    "        score[4] += 2.0 * (pc > 0.7) + 1.2 * bt\n",
    "        score[5] += 1.5 * sp * dp + 0.7 * (0.2 < pc < 0.6)\n",
    "        score[0] += 0.8 - 0.2 * (abs(pc - 0.35) + abs(bt - 0.35))\n",
    "        score += 0.05 * self.rng.randn(NUM_CLASSES)\n",
    "        return int(np.argmax(score))\n",
    "\n",
    "    # -------- Feature sampling (attack semantics + drift; no rejection) --------\n",
    "    def _sample_attack_id_one(self) -> int:\n",
    "        return int(self._attack_sampler.sample_one())\n",
    "\n",
    "    def _sample_attack_ids(self, n: int) -> np.ndarray:\n",
    "        return self._attack_sampler.sample_n(n)\n",
    "\n",
    "    def _baseline_features_one(self, trend: str):\n",
    "        if trend in ('normal', 'concept_drift'):\n",
    "            src_port = int(self.rng.randint(1024, 65535))\n",
    "            dst_port = int(self.rng.randint(1, 65535))\n",
    "            proto = str(self.rng.choice(['TCP', 'UDP']))\n",
    "            packet_count = int(self.rng.randint(1, 400))\n",
    "            conn_state = 'EST'\n",
    "            bytes_transferred = float(self.rng.uniform(1e3, 5e5))\n",
    "        else:  # data_drift\n",
    "            # Moderate covariate shift: move normals towards heavier traffic and noisier states\n",
    "            # but keep attack semantics unchanged (labels remain coherent).\n",
    "            src_port = int(1024 + (45000 - 1024) * float(self.rng.beta(a=2, b=4)))\n",
    "            dst_port = int(1 + (45000 - 1) * float(self.rng.beta(a=2, b=4)))\n",
    "            proto = str(self.rng.choice(['ICMP', 'TCP', 'UDP'], p=[0.25, 0.40, 0.35]))\n",
    "            packet_count = int(50 + (1200 - 50) * float(self.rng.beta(a=2, b=5)))\n",
    "            conn_state = str(self.rng.choice(['EST', 'SYN', 'RST'], p=[0.55, 0.35, 0.10]))\n",
    "            bytes_transferred = float(1e4 + (1.2e6 - 1e4) * float(self.rng.beta(a=2, b=5)))\n",
    "        return src_port, dst_port, proto, packet_count, conn_state, bytes_transferred\n",
    "\n",
    "    def _apply_attack_semantics_one(\n",
    "        self,\n",
    "        attack_id: int,\n",
    "        src_port: int,\n",
    "        dst_port: int,\n",
    "        proto: str,\n",
    "        packet_count: int,\n",
    "        conn_state: str,\n",
    "        bytes_transferred: float,\n",
    "    ):\n",
    "        # Deterministic-by-construction attack regions (no oracle correction).\n",
    "        if attack_id == ATTACK_TO_ID['DoS']:\n",
    "            packet_count = int(self.rng.randint(1200, 2000))\n",
    "            proto = str(self.rng.choice(['ICMP', 'UDP']))\n",
    "        elif attack_id == ATTACK_TO_ID['Probe']:\n",
    "            dst_port = int(self.rng.choice([21, 22, 23, 80, 443]))\n",
    "            packet_count = int(self.rng.randint(200, 800))\n",
    "        elif attack_id == ATTACK_TO_ID['R2L']:\n",
    "            conn_state = 'RST'\n",
    "            bytes_transferred = float(self.rng.uniform(0, 200))\n",
    "        elif attack_id == ATTACK_TO_ID['U2R']:\n",
    "            bytes_transferred = float(self.rng.uniform(8e5, 1.3e6))\n",
    "            conn_state = 'EST'\n",
    "        elif attack_id == ATTACK_TO_ID['Worm']:\n",
    "            bytes_transferred = float(self.rng.uniform(1.5e6, 2e6))\n",
    "            packet_count = int(self.rng.randint(600, 1400))\n",
    "        # Normal: keep baseline.\n",
    "        return src_port, dst_port, proto, packet_count, conn_state, bytes_transferred\n",
    "\n",
    "    def _sample_row_one(self, attack_id: int, trend: str):\n",
    "        src_port, dst_port, proto, packet_count, conn_state, bytes_transferred = self._baseline_features_one(trend)\n",
    "        src_port, dst_port, proto, packet_count, conn_state, bytes_transferred = self._apply_attack_semantics_one(\n",
    "            attack_id, src_port, dst_port, proto, packet_count, conn_state, bytes_transferred\n",
    "        )\n",
    "        if trend == 'data_drift':\n",
    "            packet_count = int(np.clip(packet_count + float(self.rng.normal(0, 80)), 1, 2000))\n",
    "            bytes_transferred = float(np.clip(bytes_transferred * float(self.rng.lognormal(mean=0.0, sigma=0.20)), 0.0, 2e6))\n",
    "        row = {\n",
    "            'src_port': int(src_port),\n",
    "            'dst_port': int(dst_port),\n",
    "            'protocol': proto,\n",
    "            'packet_count': int(packet_count),\n",
    "            'conn_state': conn_state,\n",
    "            'bytes_transferred': float(bytes_transferred),\n",
    "            'timestamp': self.next_timestamp(),\n",
    "        }\n",
    "        return row\n",
    "\n",
    "    # -------- Public single-sample API (fast, O(1), loop-free) --------\n",
    "    def produce(self, trend: str = 'normal'):\n",
    "        \"\"\"Generate exactly one JSON-friendly sample.\n",
    "\n",
    "        Requirements met:\n",
    "        - No loops\n",
    "        - No rejection sampling\n",
    "        - No oracle correction\n",
    "        - Only: sample features, deterministic label, timestamp, format output\n",
    "        \"\"\"\n",
    "        attack_id = self._sample_attack_id_one()\n",
    "        row = self._sample_row_one(attack_id, trend)\n",
    "\n",
    "        if trend == 'concept_drift':\n",
    "            label = self.fX_concept(row)\n",
    "        else:\n",
    "            label = int(attack_id)\n",
    "\n",
    "        return {\n",
    "            \"timestamp\": row[\"timestamp\"].isoformat(),\n",
    "            \"properties\": {\n",
    "                \"src_port\": int(row[\"src_port\"]),\n",
    "                \"dst_port\": int(row[\"dst_port\"]),\n",
    "                \"protocol\": row[\"protocol\"],\n",
    "                \"packet_count\": int(row[\"packet_count\"]),\n",
    "                \"conn_state\": row[\"conn_state\"],\n",
    "                \"bytes_transferred\": float(row[\"bytes_transferred\"]),\n",
    "            },\n",
    "            \"label\": int(label),\n",
    "        }\n",
    "\n",
    "    # -------- Vectorized oracles for batch (no Python loops over rows) --------\n",
    "    def _fX_concept_vec(\n",
    "        self,\n",
    "        src_port: np.ndarray,\n",
    "        dst_port: np.ndarray,\n",
    "        proto_idx: np.ndarray,\n",
    "        packet_count: np.ndarray,\n",
    "        conn_idx: np.ndarray,\n",
    "        bytes_transferred: np.ndarray,\n",
    "    ) -> np.ndarray:\n",
    "        pc = packet_count.astype(np.float64) / 2000.0\n",
    "        bt = bytes_transferred.astype(np.float64) / 2e6\n",
    "        sp = src_port.astype(np.float64) / 65535.0\n",
    "        dp = dst_port.astype(np.float64) / 65535.0\n",
    "\n",
    "        is_icmp = (proto_idx == int(self._proto_to_idx['ICMP']))\n",
    "\n",
    "        score = np.zeros((pc.size, NUM_CLASSES), dtype=np.float64)\n",
    "        score[:, 1] += 4.0 * bt + 0.8 * is_icmp.astype(np.float64) - 0.3 * pc\n",
    "        src_mod = (src_port % 1000).astype(np.float64) / 1000.0\n",
    "        score[:, 2] += 3.0 * (src_mod < 0.2).astype(np.float64) + 1.0 * np.isin(dst_port, [21, 22, 23, 80, 443]).astype(np.float64)\n",
    "        score[:, 3] += 2.0 * is_icmp.astype(np.float64) + 1.0 * ((bt > 0.05) & (bt < 0.2)).astype(np.float64)\n",
    "        score[:, 4] += 2.0 * (pc > 0.7).astype(np.float64) + 1.2 * bt\n",
    "        score[:, 5] += 1.5 * sp * dp + 0.7 * ((pc > 0.2) & (pc < 0.6)).astype(np.float64)\n",
    "        score[:, 0] += 0.8 - 0.2 * (np.abs(pc - 0.35) + np.abs(bt - 0.35))\n",
    "        score += 0.05 * self.rng.randn(pc.size, NUM_CLASSES)\n",
    "        return np.argmax(score, axis=1).astype(np.int32, copy=False)\n",
    "\n",
    "    # -------- Batch generation (vectorized; shares same distributions/semantics) --------\n",
    "    def generate_dataset(self, n: int, trend: str = 'normal'):\n",
    "        \"\"\"Generate a pandas DataFrame with an `attack` column.\n",
    "\n",
    "        Vectorized generation:\n",
    "        - Samples all attacks in bulk.\n",
    "        - Samples timestamps in bulk.\n",
    "        - Applies attack semantics via boolean masks.\n",
    "        \"\"\"\n",
    "        n = int(n)\n",
    "        attack_id = self._sample_attack_ids(n)\n",
    "        ts = self.next_timestamps(n)\n",
    "\n",
    "        # Baseline distributions\n",
    "        if trend in ('normal', 'concept_drift'):\n",
    "            src_port = self.rng.randint(1024, 65535, size=n).astype(np.int32)\n",
    "            dst_port = self.rng.randint(1, 65535, size=n).astype(np.int32)\n",
    "            proto_idx = self.rng.choice(\n",
    "                np.array([self._proto_to_idx['TCP'], self._proto_to_idx['UDP']], dtype=np.int32),\n",
    "                size=n,\n",
    "            ).astype(np.int32)\n",
    "            packet_count = self.rng.randint(1, 400, size=n).astype(np.int32)\n",
    "            conn_idx = np.full(n, self._conn_to_idx['EST'], dtype=np.int32)\n",
    "            bytes_transferred = self.rng.uniform(1e3, 5e5, size=n).astype(np.float64)\n",
    "        else:  # data_drift\n",
    "            # Moderate covariate shift (aim: val_data_drift accuracy ~0.8-0.9).\n",
    "            src_port = (1024 + (45000 - 1024) * self.rng.beta(a=2, b=4, size=n)).astype(np.int32)\n",
    "            dst_port = (1 + (45000 - 1) * self.rng.beta(a=2, b=4, size=n)).astype(np.int32)\n",
    "            proto_idx = self.rng.choice(\n",
    "                np.array([self._proto_to_idx['ICMP'], self._proto_to_idx['TCP'], self._proto_to_idx['UDP']], dtype=np.int32),\n",
    "                p=[0.25, 0.40, 0.35],\n",
    "                size=n,\n",
    "            ).astype(np.int32)\n",
    "            packet_count = (50 + (1200 - 50) * self.rng.beta(a=2, b=5, size=n)).astype(np.int32)\n",
    "            conn_idx = self.rng.choice(\n",
    "                np.array([self._conn_to_idx['EST'], self._conn_to_idx['SYN'], self._conn_to_idx['RST']], dtype=np.int32),\n",
    "                p=[0.55, 0.35, 0.10],\n",
    "                size=n,\n",
    "            ).astype(np.int32)\n",
    "            bytes_transferred = (1e4 + (1.2e6 - 1e4) * self.rng.beta(a=2, b=5, size=n)).astype(np.float64)\n",
    "\n",
    "        # Attack masks\n",
    "        m_dos = (attack_id == ATTACK_TO_ID['DoS'])\n",
    "        m_probe = (attack_id == ATTACK_TO_ID['Probe'])\n",
    "        m_r2l = (attack_id == ATTACK_TO_ID['R2L'])\n",
    "        m_u2r = (attack_id == ATTACK_TO_ID['U2R'])\n",
    "        m_worm = (attack_id == ATTACK_TO_ID['Worm'])\n",
    "\n",
    "        # Apply attack semantics (vectorized; no rejection)\n",
    "        if np.any(m_dos):\n",
    "            k = int(m_dos.sum())\n",
    "            packet_count[m_dos] = self.rng.randint(1200, 2000, size=k)\n",
    "            proto_idx[m_dos] = self.rng.choice(\n",
    "                np.array([self._proto_to_idx['ICMP'], self._proto_to_idx['UDP']], dtype=np.int32),\n",
    "                size=k,\n",
    "            )\n",
    "        if np.any(m_probe):\n",
    "            k = int(m_probe.sum())\n",
    "            dst_port[m_probe] = self.rng.choice(np.array([21, 22, 23, 80, 443], dtype=np.int32), size=k)\n",
    "            packet_count[m_probe] = self.rng.randint(200, 800, size=k)\n",
    "        if np.any(m_r2l):\n",
    "            k = int(m_r2l.sum())\n",
    "            conn_idx[m_r2l] = self._conn_to_idx['RST']\n",
    "            bytes_transferred[m_r2l] = self.rng.uniform(0, 200, size=k)\n",
    "        if np.any(m_u2r):\n",
    "            k = int(m_u2r.sum())\n",
    "            conn_idx[m_u2r] = self._conn_to_idx['EST']\n",
    "            bytes_transferred[m_u2r] = self.rng.uniform(8e5, 1.3e6, size=k)\n",
    "        if np.any(m_worm):\n",
    "            k = int(m_worm.sum())\n",
    "            bytes_transferred[m_worm] = self.rng.uniform(1.5e6, 2e6, size=k)\n",
    "            packet_count[m_worm] = self.rng.randint(600, 1400, size=k)\n",
    "        if trend == 'data_drift':\n",
    "            packet_count = np.clip(packet_count.astype(np.float64) + self.rng.normal(0, 80, size=n), 1, 2000).astype(np.int32)\n",
    "            bytes_transferred = np.clip(bytes_transferred * self.rng.lognormal(mean=0.0, sigma=0.20, size=n), 0.0, 2e6).astype(np.float64)\n",
    "\n",
    "        # Decode categoricals\n",
    "        protocol = _PROTO_VALS[proto_idx]\n",
    "        conn_state = _CONN_VALS[conn_idx]\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'src_port': src_port.astype(int),\n",
    "            'dst_port': dst_port.astype(int),\n",
    "            'protocol': protocol,\n",
    "            'packet_count': packet_count.astype(int),\n",
    "            'conn_state': conn_state,\n",
    "            'bytes_transferred': bytes_transferred.astype(float),\n",
    "            'timestamp': ts,\n",
    "        })\n",
    "\n",
    "        if trend == 'concept_drift':\n",
    "            df['attack'] = self._fX_concept_vec(\n",
    "                src_port=src_port,\n",
    "                dst_port=dst_port,\n",
    "                proto_idx=proto_idx,\n",
    "                packet_count=packet_count,\n",
    "                conn_idx=conn_idx,\n",
    "                bytes_transferred=bytes_transferred,\n",
    "            ).astype(int)\n",
    "        else:\n",
    "            df['attack'] = attack_id.astype(int)\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        return df\n",
    "\n",
    "    # Optional explicit batch API for streaming simulators\n",
    "    def produce_batch(self, n: int, trend: str = 'normal'):\n",
    "        \"\"\"Return a list of JSON-friendly dicts (like `produce()`) for integration ease.\"\"\"\n",
    "        df = self.generate_dataset(n, trend=trend)\n",
    "        out = []\n",
    "        # This loop is intentionally outside `produce()`; batch callers can stream/serialize.\n",
    "        for r in df.itertuples(index=False):\n",
    "            out.append({\n",
    "                \"timestamp\": pd.Timestamp(r.timestamp).isoformat(),\n",
    "                \"properties\": {\n",
    "                    \"src_port\": int(r.src_port),\n",
    "                    \"dst_port\": int(r.dst_port),\n",
    "                    \"protocol\": str(r.protocol),\n",
    "                    \"packet_count\": int(r.packet_count),\n",
    "                    \"conn_state\": str(r.conn_state),\n",
    "                    \"bytes_transferred\": float(r.bytes_transferred),\n",
    "                },\n",
    "                \"label\": int(r.attack),\n",
    "            })\n",
    "        return out\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# PREPROCESSING - PANDAS (large, realistic)\n",
    "# -------------------------\n",
    "def preprocess_pandas(df, fit_encoders=True, fit_scaler=True, global_stats=None):\n",
    "    \"\"\"\n",
    "    Preprocesamiento complejo estilo PySpark-ready:\n",
    "    - Categóricas -> LabelEncoder\n",
    "    - Features log-transform / ratios\n",
    "    - Rolling/window stats por session\n",
    "    - Estadísticas globales (mean/std) para normalización\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) timestamp -> segundos desde epoch\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['timestamp_epoch'] = df['timestamp'].astype('int64') // 10**9\n",
    "\n",
    "    # 2) crear feature log + small offset para evitar log(0)\n",
    "    df['bytes_log'] = np.log1p(df['bytes_transferred'])\n",
    "    df['packet_log'] = np.log1p(df['packet_count'])\n",
    "\n",
    "    # 3) ratios\n",
    "    df['bytes_per_packet'] = df['bytes_transferred'] / (df['packet_count'] + 1)\n",
    "    df['bytes_per_packet_log'] = np.log1p(df['bytes_per_packet'])\n",
    "\n",
    "    # 4) session_id: combinación de src_port + dst_port + protocol (puede traducirse a PySpark)\n",
    "    df['session_id'] = df['src_port'].astype(str) + '-' + df['dst_port'].astype(str) + '-' + df['protocol']\n",
    "\n",
    "    # 5) rolling stats por sesión (usando transform para mantener índice)\n",
    "    df['prev_bytes_mean_3'] = df.groupby('session_id')['bytes_log'] \\\n",
    "                                .transform(lambda s: s.shift().rolling(3, min_periods=1).mean())\n",
    "    df['prev_packet_mean_3'] = df.groupby('session_id')['packet_log'] \\\n",
    "                                 .transform(lambda s: s.shift().rolling(3, min_periods=1).mean())\n",
    "    df['prev_event_count_3'] = df.groupby('session_id')['packet_count'] \\\n",
    "                                  .transform(lambda s: s.shift().rolling(3, min_periods=1).count())\n",
    "\n",
    "    # 6) features agregadas por session (global session stats)\n",
    "    df['session_bytes_max'] = df.groupby('session_id')['bytes_log'].transform('max')\n",
    "    df['session_bytes_min'] = df.groupby('session_id')['bytes_log'].transform('min')\n",
    "    df['session_packet_mean'] = df.groupby('session_id')['packet_log'].transform('mean')\n",
    "\n",
    "    # 7) rolling stats pueden producir NaN en los primeros eventos de cada sesión\n",
    "    roll_cols = ['prev_bytes_mean_3', 'prev_packet_mean_3', 'prev_event_count_3']\n",
    "    df[roll_cols] = df[roll_cols].fillna(0)\n",
    "\n",
    "    # 8) codificación de categóricas (fit nuevo o reusar encoders existentes)\n",
    "    if isinstance(fit_encoders, dict):\n",
    "        encoders = fit_encoders\n",
    "        fit_new_encoders = False\n",
    "    else:\n",
    "        encoders = {}\n",
    "        fit_new_encoders = bool(fit_encoders)\n",
    "\n",
    "    for col in ['protocol', 'conn_state']:\n",
    "        if fit_new_encoders:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "            encoders[col] = le\n",
    "        else:\n",
    "            le = encoders[col]\n",
    "            mapping = {cls: int(i) for i, cls in enumerate(le.classes_)}\n",
    "            df[col] = df[col].map(mapping).fillna(-1).astype(int)\n",
    "\n",
    "    # 9) columnas finales para modelado (antes de normalizar)\n",
    "    base_feature_cols = ['src_port', 'dst_port', 'packet_count', 'bytes_transferred', 'bytes_log', 'packet_log',\n",
    "                         'bytes_per_packet', 'bytes_per_packet_log',\n",
    "                         'prev_bytes_mean_3', 'prev_packet_mean_3', 'prev_event_count_3',\n",
    "                         'session_bytes_max', 'session_bytes_min', 'session_packet_mean',\n",
    "                         'protocol', 'conn_state', 'timestamp_epoch']\n",
    "\n",
    "    # 10) escalado: aceptar `fit_scaler=True` (fit) o un StandardScaler ya entrenado\n",
    "    X = df[base_feature_cols].fillna(0).values\n",
    "    if isinstance(fit_scaler, StandardScaler):\n",
    "        scaler = fit_scaler\n",
    "    elif bool(fit_scaler):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    else:\n",
    "        scaler = None\n",
    "\n",
    "    if scaler is not None:\n",
    "        Xs = scaler.transform(X)\n",
    "        global_stats = {\n",
    "            f: {'mean': float(scaler.mean_[i]), 'std': float(scaler.scale_[i])}\n",
    "            for i, f in enumerate(base_feature_cols)\n",
    "        }\n",
    "        for i, f in enumerate(base_feature_cols):\n",
    "            df[f + '_norm'] = Xs[:, i]\n",
    "    else:\n",
    "        # fallback: usar stats provistas o calcularlas desde el df\n",
    "        if global_stats is None:\n",
    "            global_stats = {f: {'mean': df[f].mean(), 'std': df[f].std()} for f in base_feature_cols}\n",
    "        for f in base_feature_cols:\n",
    "            df[f + '_norm'] = (df[f].fillna(0) - global_stats[f]['mean']) / (global_stats[f]['std'] + 1e-6)\n",
    "\n",
    "    feature_cols = [f + '_norm' for f in base_feature_cols]\n",
    "    return df, encoders, scaler, global_stats, feature_cols\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Pyspark equivalent preprocessing (if you want distributed)\n",
    "# -------------------------\n",
    "def preprocess_spark(spark, spark_df):\n",
    "    \"\"\"\n",
    "    Example PySpark pipeline equivalent. This returns a Spark DataFrame with similar derived features.\n",
    "    This function is illustrative; to run it you need pyspark configured.\n",
    "    \"\"\"\n",
    "    from pyspark.sql import functions as F\n",
    "    from pyspark.sql.window import Window\n",
    "    from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "\n",
    "    df = spark_df\n",
    "    # time features\n",
    "    df = df.withColumn('timestamp_ts', F.col('timestamp').cast('timestamp'))\n",
    "    df = df.withColumn('hour', F.hour('timestamp_ts'))\n",
    "    df = df.withColumn('dayofweek', F.dayofweek('timestamp_ts') - 1)  # pyspark dayofweek 1..7\n",
    "    df = df.withColumn('is_weekend', F.when(F.col('dayofweek').isin(5, 6), 1).otherwise(0))\n",
    "    # sin/cos for hour\n",
    "    df = df.withColumn('hour_sin', F.sin(2 * 3.1415926535 * F.col('hour') / F.lit(24.0)))\n",
    "    df = df.withColumn('hour_cos', F.cos(2 * 3.1415926535 * F.col('hour') / F.lit(24.0)))\n",
    "\n",
    "    # flags\n",
    "    well_known = [21, 22, 23, 25, 53, 80, 110, 143, 443]\n",
    "    df = df.withColumn('dst_well_known', F.when(F.col('dst_port').isin(well_known), 1).otherwise(0))\n",
    "    df = df.withColumn('src_port_bucket', (F.col('src_port') / 10000).cast('int'))\n",
    "\n",
    "    # logs & ratios\n",
    "    df = df.withColumn('bytes_log', F.log1p(F.col('bytes_transferred')))\n",
    "    df = df.withColumn('packet_log', F.log1p(F.col('packet_count')))\n",
    "    df = df.withColumn('pkt_per_byte', F.col('packet_count') / (F.col('bytes_transferred') + F.lit(1.0)))\n",
    "\n",
    "    # crosses\n",
    "    df = df.withColumn('protocol_conn', F.concat_ws('_', F.col('protocol'), F.col('conn_state')))\n",
    "\n",
    "    # session id\n",
    "    df = df.withColumn('session_id', F.concat_ws('_', F.col('src_port').cast('string'), F.col('dst_port').cast('string'), F.col('protocol')))\n",
    "\n",
    "    # window functions per session (previous 3 events)\n",
    "    w = Window.partitionBy('session_id').orderBy('timestamp_ts').rowsBetween(-3, -1)\n",
    "    df = df.withColumn('prev_bytes_mean_3', F.avg('bytes_log').over(w))\n",
    "    df = df.withColumn('prev_packet_mean_3', F.avg('packet_log').over(w))\n",
    "    df = df.withColumn('prev_event_count_3', F.count('packet_count').over(w))\n",
    "\n",
    "    # encode categorical columns using StringIndexer (example)\n",
    "    protocol_indexer = StringIndexer(inputCol='protocol', outputCol='protocol_idx').fit(df)\n",
    "    df = protocol_indexer.transform(df)\n",
    "    conn_indexer = StringIndexer(inputCol='conn_state', outputCol='conn_state_idx').fit(df)\n",
    "    df = conn_indexer.transform(df)\n",
    "    pc_indexer = StringIndexer(inputCol='protocol_conn', outputCol='protocol_conn_idx').fit(df)\n",
    "    df = pc_indexer.transform(df)\n",
    "\n",
    "    # choose features and assemble\n",
    "    feat_cols = ['src_port', 'dst_port', 'packet_count', 'bytes_transferred', 'bytes_log', 'packet_log', 'pkt_per_byte',\n",
    "                 'hour', 'dayofweek', 'is_weekend', 'hour_sin', 'hour_cos',\n",
    "                 'dst_well_known', 'src_port_bucket', 'protocol_idx', 'conn_state_idx', 'protocol_conn_idx',\n",
    "                 'prev_bytes_mean_3', 'prev_packet_mean_3', 'prev_event_count_3']\n",
    "    assembler = VectorAssembler(inputCols=feat_cols, outputCol='features_vec')\n",
    "    df = assembler.transform(df)\n",
    "\n",
    "    # standardize\n",
    "    scaler = StandardScaler(inputCol='features_vec', outputCol='features_scaled', withMean=True, withStd=True)\n",
    "    scaler_model = scaler.fit(df)\n",
    "    df = scaler_model.transform(df)\n",
    "\n",
    "    return df  # features in 'features_scaled' vector\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Helper: try to save Parquet (simulate distributed storage)\n",
    "# -------------------------\n",
    "def save_parquet(df, path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    df.to_parquet(path, index=False)\n",
    "    print(f\"Saved parquet to {path}\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Full demo pipeline (generate -> preprocess -> train) using pandas preprocess\n",
    "# -------------------------\n",
    "def run_demo():\n",
    "    gen = SyntheticTrafficGenerator(start_ts=\"2026-01-12 18:00:00\", epsilon_seconds=60, rng=RNG)\n",
    "    TRAIN_N, VAL_N = 2000, 3000\n",
    "\n",
    "    print(\"Generating datasets...\")\n",
    "    df_train = gen.generate_dataset(TRAIN_N, trend='normal')\n",
    "    df_val_normal = gen.generate_dataset(VAL_N, trend='normal')\n",
    "    df_val_data = gen.generate_dataset(VAL_N, trend='data_drift')\n",
    "    df_val_concept = gen.generate_dataset(VAL_N, trend='concept_drift')\n",
    "\n",
    "    # optionally save to parquet for distributed load\n",
    "    save_parquet(df_train, \"out/train.parquet\")\n",
    "    save_parquet(df_val_normal, \"out/val_normal.parquet\")\n",
    "    save_parquet(df_val_data, \"out/val_data.parquet\")\n",
    "    save_parquet(df_val_concept, \"out/val_concept.parquet\")\n",
    "\n",
    "    # build concept_train (val_normal features relabeled by concept)\n",
    "    df_concept_train = df_val_normal.copy()\n",
    "    # Keep prior behavior (concept oracle over normal-distribution features), but vectorized for scale.\n",
    "    proto_idx = df_concept_train['protocol'].map(gen._proto_to_idx).astype(np.int32).values\n",
    "    conn_idx = df_concept_train['conn_state'].map(gen._conn_to_idx).astype(np.int32).values\n",
    "    df_concept_train['attack'] = gen._fX_concept_vec(\n",
    "        src_port=df_concept_train['src_port'].astype(np.int32).values,\n",
    "        dst_port=df_concept_train['dst_port'].astype(np.int32).values,\n",
    "        proto_idx=proto_idx,\n",
    "        packet_count=df_concept_train['packet_count'].astype(np.int32).values,\n",
    "        conn_idx=conn_idx,\n",
    "        bytes_transferred=df_concept_train['bytes_transferred'].astype(np.float64).values,\n",
    "    ).astype(int)\n",
    "\n",
    "    # preprocess train (fits encoders/scaler)\n",
    "    print(\"Preprocessing train (Pandas)...\")\n",
    "    df_train_proc, encoders, scaler, global_stats, feature_cols = preprocess_pandas(df_train)\n",
    "\n",
    "    # preprocess val using same encoders/scaler / global_stats\n",
    "    print(\"Preprocessing val_normal (Pandas)...\")\n",
    "    df_valn_proc, _, _, _, _ = preprocess_pandas(df_val_normal, fit_encoders=encoders, fit_scaler=scaler, global_stats=global_stats)\n",
    "    df_vald_proc, _, _, _, _ = preprocess_pandas(df_val_data, fit_encoders=encoders, fit_scaler=scaler, global_stats=global_stats)\n",
    "    df_valc_proc, _, _, _, _ = preprocess_pandas(df_val_concept, fit_encoders=encoders, fit_scaler=scaler, global_stats=global_stats)\n",
    "    df_concept_train_proc, _, _, _, _ = preprocess_pandas(df_concept_train, fit_encoders=encoders, fit_scaler=scaler, global_stats=global_stats)\n",
    "\n",
    "    # optionally save to parquet for distributed load\n",
    "    #save_parquet(df_train_proc, \"out/train_proc.parquet\")\n",
    "    #save_parquet(df_valn_proc, \"out/val_normal_proc.parquet\")\n",
    "    #save_parquet(df_vald_proc, \"out/val_data_proc.parquet\")\n",
    "    #save_parquet(df_valc_proc, \"out/val_concept_proc.parquet\")\n",
    "\n",
    "    # prepare arrays for xgboost (use feature_cols returned by preprocess)\n",
    "    X_train = df_train_proc[feature_cols].values\n",
    "    y_train = df_train_proc['attack'].values\n",
    "    Xn = df_valn_proc[feature_cols].values\n",
    "    yn = df_valn_proc['attack'].values\n",
    "    Xd = df_vald_proc[feature_cols].values\n",
    "    yd = df_vald_proc['attack'].values\n",
    "    Xc = df_valc_proc[feature_cols].values\n",
    "    yc = df_valc_proc['attack'].values\n",
    "\n",
    "    # train helper (GPU fallback)\n",
    "    def train_xgb(X_tr, y_tr, eval_set):\n",
    "        params = {\n",
    "            'n_estimators': 100,\n",
    "            'max_depth': 7,\n",
    "            'learning_rate': 0.1,\n",
    "            'objective': 'multi:softprob',\n",
    "            'num_class': NUM_CLASSES,\n",
    "            'verbosity': 1,\n",
    "            'eval_metric': ['mlogloss', 'merror'],\n",
    "        }\n",
    "        try:\n",
    "            model = xgb.XGBClassifier(**params, tree_method='hist', device='gpu')\n",
    "            model.fit(X_tr, y_tr, eval_set=eval_set, verbose=False)\n",
    "            print(\"Trained with GPU.\")\n",
    "        except Exception as e:\n",
    "            print(\"GPU failed:\", e, \"Falling back to CPU.\")\n",
    "            model = xgb.XGBClassifier(**params, tree_method='hist', device='cpu')\n",
    "            model.fit(X_tr, y_tr, eval_set=eval_set, verbose=False)\n",
    "        return model\n",
    "\n",
    "    print(\"\\n=== EXP: train on normal, eval on normal/data/concept ===\")\n",
    "    model_norm = train_xgb(X_train, y_train, eval_set=[(Xn, yn)])\n",
    "\n",
    "    def run_report(m, Xv, yv, name):\n",
    "        ypred = m.predict(Xv)\n",
    "        print(f\"\\n--- {name} --- Accuracy: {accuracy_score(yv, ypred):.4f}\")\n",
    "        print(classification_report(yv, ypred, target_names=[ATTACK_LABELS[i] for i in range(NUM_CLASSES)], digits=4))\n",
    "\n",
    "    run_report(model_norm, Xn, yn, \"val_normal\")\n",
    "    run_report(model_norm, Xd, yd, \"val_data_drift\")\n",
    "    run_report(model_norm, Xc, yc, \"val_concept_drift\")\n",
    "\n",
    "    # retrain on concept (as before)\n",
    "    print(\"\\n=== EXP: retrain on concept (using df_concept_train_proc) ===\")\n",
    "    X_concept_train = df_concept_train_proc[feature_cols].values\n",
    "    y_concept_train = df_concept_train_proc['attack'].values\n",
    "    X_concept_val = df_valc_proc[feature_cols].values\n",
    "    y_concept_val = df_valc_proc['attack'].values\n",
    "    model_concept = train_xgb(X_concept_train, y_concept_train, eval_set=[(X_concept_val, y_concept_val)])\n",
    "    run_report(model_concept, X_concept_val, y_concept_val, \"concept_val (after retrain)\")\n",
    "\n",
    "    print(\"\\nSample processed train head:\")\n",
    "    print(df_train_proc.head(6))\n",
    "    print(\"\\nFeature columns used:\", feature_cols)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Entrypoint\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_demo()\n",
    "\n",
    "    # if you want to try the pyspark pipeline, uncomment next lines (requires pyspark installed/configured):\n",
    "    # from pyspark.sql import SparkSession\n",
    "    # spark = SparkSession.builder.master(\"local[4]\").appName(\"synth\").getOrCreate()\n",
    "    # df_train_spark = spark.read.parquet(\"out/train_proc.parquet\")\n",
    "    # df_train_spark.show(5)\n",
    "    # spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fb4e74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "6c42c8f2-dbf9-4e30-a83a-21126fbdeb42",
       "rows": [
        [
         "0",
         "9400"
        ],
        [
         "1",
         "193"
        ],
        [
         "3",
         "152"
        ],
        [
         "2",
         "126"
        ],
        [
         "4",
         "85"
        ],
        [
         "5",
         "44"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 6
       }
      },
      "text/plain": [
       "label\n",
       "0    9400\n",
       "1     193\n",
       "3     152\n",
       "2     126\n",
       "4      85\n",
       "5      44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# producer method returning JSON-like dict\n",
    "producer = SyntheticTrafficGenerator(start_ts= \"2026-01-12 18:00:00\", epsilon_seconds= 100, rng= RNG)\n",
    "\n",
    "outputs = []\n",
    "for _ in range(10000):\n",
    "    outputs.append(producer.produce(trend='normal'))\n",
    "\n",
    "df_output = pd.DataFrame(outputs)\n",
    "df_output['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73b93f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "properties",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "62ac6a41-3111-4c6e-923d-686f7a325e6f",
       "rows": [
        [
         "0",
         "2026-01-12T18:01:22.000000751",
         "{'src_port': 47116, 'dst_port': 58479, 'protocol': 'UDP', 'packet_count': 124, 'conn_state': 'EST', 'bytes_transferred': 163444.06452416477}",
         "0"
        ],
        [
         "1",
         "2026-01-12T18:01:43.000000605",
         "{'src_port': 50868, 'dst_port': 57682, 'protocol': 'TCP', 'packet_count': 82, 'conn_state': 'EST', 'bytes_transferred': 167851.51342200735}",
         "0"
        ],
        [
         "2",
         "2026-01-12T18:03:36.000000236",
         "{'src_port': 56232, 'dst_port': 14910, 'protocol': 'TCP', 'packet_count': 98, 'conn_state': 'EST', 'bytes_transferred': 431843.5021662479}",
         "0"
        ],
        [
         "3",
         "2026-01-12T18:05:13.000000090",
         "{'src_port': 15575, 'dst_port': 63430, 'protocol': 'TCP', 'packet_count': 207, 'conn_state': 'EST', 'bytes_transferred': 81956.29780371269}",
         "0"
        ],
        [
         "4",
         "2026-01-12T18:07:19.000000017",
         "{'src_port': 59834, 'dst_port': 29222, 'protocol': 'UDP', 'packet_count': 127, 'conn_state': 'EST', 'bytes_transferred': 298735.97192607884}",
         "0"
        ],
        [
         "5",
         "2026-01-12T18:08:23.000000298",
         "{'src_port': 13065, 'dst_port': 11651, 'protocol': 'UDP', 'packet_count': 1498, 'conn_state': 'EST', 'bytes_transferred': 260478.55794962318}",
         "1"
        ],
        [
         "6",
         "2026-01-12T18:11:06.000000617",
         "{'src_port': 7551, 'dst_port': 59767, 'protocol': 'TCP', 'packet_count': 11, 'conn_state': 'EST', 'bytes_transferred': 173416.6009691803}",
         "0"
        ],
        [
         "7",
         "2026-01-12T18:13:11.000000392",
         "{'src_port': 49559, 'dst_port': 63236, 'protocol': 'TCP', 'packet_count': 39, 'conn_state': 'EST', 'bytes_transferred': 207240.05760732436}",
         "0"
        ],
        [
         "8",
         "2026-01-12T18:13:43.000000358",
         "{'src_port': 57967, 'dst_port': 47490, 'protocol': 'TCP', 'packet_count': 101, 'conn_state': 'EST', 'bytes_transferred': 278783.26709416363}",
         "0"
        ],
        [
         "9",
         "2026-01-12T18:16:34.000000691",
         "{'src_port': 59358, 'dst_port': 28261, 'protocol': 'UDP', 'packet_count': 95, 'conn_state': 'EST', 'bytes_transferred': 476846.8284287049}",
         "0"
        ],
        [
         "10",
         "2026-01-12T18:17:44.000000193",
         "{'src_port': 39670, 'dst_port': 54725, 'protocol': 'TCP', 'packet_count': 285, 'conn_state': 'EST', 'bytes_transferred': 245928.7470503701}",
         "0"
        ],
        [
         "11",
         "2026-01-12T18:18:47.000000122",
         "{'src_port': 4540, 'dst_port': 27612, 'protocol': 'TCP', 'packet_count': 275, 'conn_state': 'EST', 'bytes_transferred': 334158.8017486419}",
         "0"
        ],
        [
         "12",
         "2026-01-12T18:20:37.000000675",
         "{'src_port': 30694, 'dst_port': 3902, 'protocol': 'TCP', 'packet_count': 56, 'conn_state': 'EST', 'bytes_transferred': 357977.1908766295}",
         "0"
        ],
        [
         "13",
         "2026-01-12T18:23:03.000000416",
         "{'src_port': 46576, 'dst_port': 1190, 'protocol': 'TCP', 'packet_count': 375, 'conn_state': 'EST', 'bytes_transferred': 405390.13476583775}",
         "0"
        ],
        [
         "14",
         "2026-01-12T18:24:53.000000384",
         "{'src_port': 10705, 'dst_port': 53083, 'protocol': 'TCP', 'packet_count': 46, 'conn_state': 'EST', 'bytes_transferred': 432837.5397983136}",
         "0"
        ],
        [
         "15",
         "2026-01-12T18:26:22.000000444",
         "{'src_port': 48927, 'dst_port': 27380, 'protocol': 'TCP', 'packet_count': 243, 'conn_state': 'EST', 'bytes_transferred': 294119.80992123386}",
         "0"
        ],
        [
         "16",
         "2026-01-12T18:26:57.000000584",
         "{'src_port': 45652, 'dst_port': 48863, 'protocol': 'UDP', 'packet_count': 359, 'conn_state': 'EST', 'bytes_transferred': 73178.02305881343}",
         "0"
        ],
        [
         "17",
         "2026-01-12T18:29:54.000000750",
         "{'src_port': 31040, 'dst_port': 24971, 'protocol': 'TCP', 'packet_count': 48, 'conn_state': 'EST', 'bytes_transferred': 238854.76226973344}",
         "0"
        ],
        [
         "18",
         "2026-01-12T18:30:12.000000929",
         "{'src_port': 47095, 'dst_port': 4889, 'protocol': 'UDP', 'packet_count': 53, 'conn_state': 'EST', 'bytes_transferred': 390668.5221993371}",
         "0"
        ],
        [
         "19",
         "2026-01-12T18:31:58.000000417",
         "{'src_port': 6586, 'dst_port': 18705, 'protocol': 'TCP', 'packet_count': 114, 'conn_state': 'EST', 'bytes_transferred': 221200.71733290344}",
         "0"
        ],
        [
         "20",
         "2026-01-12T18:33:35.000000020",
         "{'src_port': 61121, 'dst_port': 22, 'protocol': 'UDP', 'packet_count': 448, 'conn_state': 'EST', 'bytes_transferred': 241888.6979019918}",
         "2"
        ],
        [
         "21",
         "2026-01-12T18:35:45.000000875",
         "{'src_port': 27236, 'dst_port': 21, 'protocol': 'UDP', 'packet_count': 636, 'conn_state': 'EST', 'bytes_transferred': 87380.43697652883}",
         "2"
        ],
        [
         "22",
         "2026-01-12T18:37:12.000000159",
         "{'src_port': 45952, 'dst_port': 53698, 'protocol': 'TCP', 'packet_count': 154, 'conn_state': 'EST', 'bytes_transferred': 439463.6505226244}",
         "0"
        ],
        [
         "23",
         "2026-01-12T18:39:18.000000589",
         "{'src_port': 10912, 'dst_port': 48779, 'protocol': 'UDP', 'packet_count': 216, 'conn_state': 'EST', 'bytes_transferred': 78035.61061738999}",
         "0"
        ],
        [
         "24",
         "2026-01-12T18:41:01.000000709",
         "{'src_port': 17335, 'dst_port': 35007, 'protocol': 'UDP', 'packet_count': 300, 'conn_state': 'EST', 'bytes_transferred': 227835.40611413534}",
         "0"
        ],
        [
         "25",
         "2026-01-12T18:43:15.000000696",
         "{'src_port': 47250, 'dst_port': 39371, 'protocol': 'TCP', 'packet_count': 360, 'conn_state': 'EST', 'bytes_transferred': 150475.9531664789}",
         "0"
        ],
        [
         "26",
         "2026-01-12T18:43:38.000000409",
         "{'src_port': 14087, 'dst_port': 35733, 'protocol': 'UDP', 'packet_count': 41, 'conn_state': 'EST', 'bytes_transferred': 15777.312920458953}",
         "0"
        ],
        [
         "27",
         "2026-01-12T18:46:00.000000349",
         "{'src_port': 60452, 'dst_port': 50116, 'protocol': 'UDP', 'packet_count': 30, 'conn_state': 'EST', 'bytes_transferred': 409740.47584660776}",
         "0"
        ],
        [
         "28",
         "2026-01-12T18:47:32.000000590",
         "{'src_port': 16229, 'dst_port': 23394, 'protocol': 'TCP', 'packet_count': 193, 'conn_state': 'EST', 'bytes_transferred': 195785.31039506992}",
         "0"
        ],
        [
         "29",
         "2026-01-12T18:49:29.000000474",
         "{'src_port': 32567, 'dst_port': 4790, 'protocol': 'TCP', 'packet_count': 8, 'conn_state': 'EST', 'bytes_transferred': 30154.522447467352}",
         "0"
        ],
        [
         "30",
         "2026-01-12T18:51:16.000000433",
         "{'src_port': 59270, 'dst_port': 36885, 'protocol': 'UDP', 'packet_count': 169, 'conn_state': 'EST', 'bytes_transferred': 378675.60092094477}",
         "0"
        ],
        [
         "31",
         "2026-01-12T18:51:44.000000277",
         "{'src_port': 36614, 'dst_port': 14795, 'protocol': 'TCP', 'packet_count': 113, 'conn_state': 'EST', 'bytes_transferred': 159571.38188390885}",
         "0"
        ],
        [
         "32",
         "2026-01-12T18:54:37.000000737",
         "{'src_port': 40984, 'dst_port': 42013, 'protocol': 'UDP', 'packet_count': 182, 'conn_state': 'EST', 'bytes_transferred': 176066.39425734666}",
         "0"
        ],
        [
         "33",
         "2026-01-12T18:56:15.000000405",
         "{'src_port': 4623, 'dst_port': 10524, 'protocol': 'TCP', 'packet_count': 108, 'conn_state': 'EST', 'bytes_transferred': 329813.32866999815}",
         "0"
        ],
        [
         "34",
         "2026-01-12T18:57:24.000000839",
         "{'src_port': 23586, 'dst_port': 486, 'protocol': 'UDP', 'packet_count': 22, 'conn_state': 'EST', 'bytes_transferred': 471146.97565946955}",
         "0"
        ],
        [
         "35",
         "2026-01-12T18:59:20.000000289",
         "{'src_port': 25166, 'dst_port': 60965, 'protocol': 'UDP', 'packet_count': 25, 'conn_state': 'EST', 'bytes_transferred': 187565.4522801446}",
         "0"
        ],
        [
         "36",
         "2026-01-12T19:01:18.000000618",
         "{'src_port': 12027, 'dst_port': 42600, 'protocol': 'UDP', 'packet_count': 313, 'conn_state': 'EST', 'bytes_transferred': 408198.83712171693}",
         "0"
        ],
        [
         "37",
         "2026-01-12T19:01:42.000000724",
         "{'src_port': 46921, 'dst_port': 62348, 'protocol': 'UDP', 'packet_count': 347, 'conn_state': 'EST', 'bytes_transferred': 32562.90112582782}",
         "0"
        ],
        [
         "38",
         "2026-01-12T19:04:13.000000419",
         "{'src_port': 2279, 'dst_port': 60449, 'protocol': 'UDP', 'packet_count': 102, 'conn_state': 'EST', 'bytes_transferred': 410301.5191198943}",
         "0"
        ],
        [
         "39",
         "2026-01-12T19:06:20.000000432",
         "{'src_port': 50885, 'dst_port': 22330, 'protocol': 'TCP', 'packet_count': 23, 'conn_state': 'EST', 'bytes_transferred': 474574.9804587065}",
         "0"
        ],
        [
         "40",
         "2026-01-12T19:08:16.000000492",
         "{'src_port': 54151, 'dst_port': 14418, 'protocol': 'UDP', 'packet_count': 80, 'conn_state': 'EST', 'bytes_transferred': 151549.6075266254}",
         "0"
        ],
        [
         "41",
         "2026-01-12T19:08:57.000000165",
         "{'src_port': 22261, 'dst_port': 18570, 'protocol': 'UDP', 'packet_count': 78, 'conn_state': 'EST', 'bytes_transferred': 358068.8680760848}",
         "0"
        ],
        [
         "42",
         "2026-01-12T19:10:58.000000389",
         "{'src_port': 61241, 'dst_port': 28851, 'protocol': 'TCP', 'packet_count': 380, 'conn_state': 'EST', 'bytes_transferred': 17781.465974468883}",
         "0"
        ],
        [
         "43",
         "2026-01-12T19:12:14.000000319",
         "{'src_port': 26268, 'dst_port': 59617, 'protocol': 'TCP', 'packet_count': 153, 'conn_state': 'EST', 'bytes_transferred': 84419.31718378268}",
         "0"
        ],
        [
         "44",
         "2026-01-12T19:14:54.000000476",
         "{'src_port': 64576, 'dst_port': 48561, 'protocol': 'UDP', 'packet_count': 306, 'conn_state': 'EST', 'bytes_transferred': 105452.02232221891}",
         "0"
        ],
        [
         "45",
         "2026-01-12T19:16:26.000000709",
         "{'src_port': 50688, 'dst_port': 22, 'protocol': 'UDP', 'packet_count': 666, 'conn_state': 'EST', 'bytes_transferred': 407555.7628721726}",
         "2"
        ],
        [
         "46",
         "2026-01-12T19:18:12.000000243",
         "{'src_port': 20091, 'dst_port': 47930, 'protocol': 'TCP', 'packet_count': 176, 'conn_state': 'EST', 'bytes_transferred': 265290.55849375046}",
         "0"
        ],
        [
         "47",
         "2026-01-12T19:19:21.000000085",
         "{'src_port': 57930, 'dst_port': 39006, 'protocol': 'UDP', 'packet_count': 291, 'conn_state': 'EST', 'bytes_transferred': 251156.36475919807}",
         "0"
        ],
        [
         "48",
         "2026-01-12T19:20:19.000000281",
         "{'src_port': 48787, 'dst_port': 48887, 'protocol': 'UDP', 'packet_count': 249, 'conn_state': 'EST', 'bytes_transferred': 257867.09199980463}",
         "0"
        ],
        [
         "49",
         "2026-01-12T19:21:49.000000490",
         "{'src_port': 11299, 'dst_port': 46494, 'protocol': 'TCP', 'packet_count': 286, 'conn_state': 'EST', 'bytes_transferred': 333619.6807769072}",
         "0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>properties</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-12T18:01:22.000000751</td>\n",
       "      <td>{'src_port': 47116, 'dst_port': 58479, 'protoc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-12T18:01:43.000000605</td>\n",
       "      <td>{'src_port': 50868, 'dst_port': 57682, 'protoc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-12T18:03:36.000000236</td>\n",
       "      <td>{'src_port': 56232, 'dst_port': 14910, 'protoc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-12T18:05:13.000000090</td>\n",
       "      <td>{'src_port': 15575, 'dst_port': 63430, 'protoc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-01-12T18:07:19.000000017</td>\n",
       "      <td>{'src_port': 59834, 'dst_port': 29222, 'protoc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2026-01-24T07:39:39.000000396</td>\n",
       "      <td>{'src_port': 26355, 'dst_port': 18439, 'protoc...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2026-01-24T07:40:17.000000218</td>\n",
       "      <td>{'src_port': 28504, 'dst_port': 10880, 'protoc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2026-01-24T07:42:06.000000976</td>\n",
       "      <td>{'src_port': 43586, 'dst_port': 15772, 'protoc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2026-01-24T07:44:10.000000990</td>\n",
       "      <td>{'src_port': 37432, 'dst_port': 35668, 'protoc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2026-01-24T07:45:45.000000941</td>\n",
       "      <td>{'src_port': 12495, 'dst_port': 10958, 'protoc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  \\\n",
       "0     2026-01-12T18:01:22.000000751   \n",
       "1     2026-01-12T18:01:43.000000605   \n",
       "2     2026-01-12T18:03:36.000000236   \n",
       "3     2026-01-12T18:05:13.000000090   \n",
       "4     2026-01-12T18:07:19.000000017   \n",
       "...                             ...   \n",
       "9995  2026-01-24T07:39:39.000000396   \n",
       "9996  2026-01-24T07:40:17.000000218   \n",
       "9997  2026-01-24T07:42:06.000000976   \n",
       "9998  2026-01-24T07:44:10.000000990   \n",
       "9999  2026-01-24T07:45:45.000000941   \n",
       "\n",
       "                                             properties  label  \n",
       "0     {'src_port': 47116, 'dst_port': 58479, 'protoc...      0  \n",
       "1     {'src_port': 50868, 'dst_port': 57682, 'protoc...      0  \n",
       "2     {'src_port': 56232, 'dst_port': 14910, 'protoc...      0  \n",
       "3     {'src_port': 15575, 'dst_port': 63430, 'protoc...      0  \n",
       "4     {'src_port': 59834, 'dst_port': 29222, 'protoc...      0  \n",
       "...                                                 ...    ...  \n",
       "9995  {'src_port': 26355, 'dst_port': 18439, 'protoc...      3  \n",
       "9996  {'src_port': 28504, 'dst_port': 10880, 'protoc...      0  \n",
       "9997  {'src_port': 43586, 'dst_port': 15772, 'protoc...      0  \n",
       "9998  {'src_port': 37432, 'dst_port': 35668, 'protoc...      0  \n",
       "9999  {'src_port': 12495, 'dst_port': 10958, 'protoc...      0  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b77c2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "src_port",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dst_port",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "protocol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "packet_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "conn_state",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bytes_transferred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "timestamp",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "attack",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "10fb6aea-94f5-4adc-b218-6f83d4a358a3",
       "rows": [
        [
         "0",
         "48364",
         "35671",
         "TCP",
         "218",
         "EST",
         "491361.4315560715",
         "2026-01-12 18:00:32",
         "0"
        ],
        [
         "1",
         "18818",
         "62148",
         "TCP",
         "373",
         "EST",
         "430263.6576777548",
         "2026-01-12 18:01:31",
         "0"
        ],
        [
         "2",
         "20905",
         "32564",
         "TCP",
         "31",
         "EST",
         "344261.4240940585",
         "2026-01-12 18:02:21",
         "0"
        ],
        [
         "3",
         "21780",
         "46160",
         "UDP",
         "368",
         "EST",
         "469436.19425163657",
         "2026-01-12 18:03:40",
         "0"
        ],
        [
         "4",
         "41186",
         "36487",
         "TCP",
         "47",
         "EST",
         "361433.2729935302",
         "2026-01-12 18:04:45",
         "0"
        ],
        [
         "5",
         "30440",
         "22",
         "UDP",
         "1285",
         "EST",
         "96038.04151799291",
         "2026-01-12 18:05:00",
         "1"
        ],
        [
         "6",
         "50727",
         "34269",
         "UDP",
         "108",
         "EST",
         "221635.91291829306",
         "2026-01-12 18:06:12",
         "0"
        ],
        [
         "7",
         "45378",
         "80",
         "UDP",
         "213",
         "EST",
         "36680.00914148604",
         "2026-01-12 18:07:42",
         "2"
        ],
        [
         "8",
         "26776",
         "15800",
         "TCP",
         "327",
         "EST",
         "195439.0537217696",
         "2026-01-12 18:08:23",
         "0"
        ],
        [
         "9",
         "13950",
         "26337",
         "TCP",
         "108",
         "EST",
         "371059.90684886713",
         "2026-01-12 18:09:39",
         "0"
        ],
        [
         "10",
         "54508",
         "3642",
         "UDP",
         "309",
         "EST",
         "193835.23211447787",
         "2026-01-12 18:10:20",
         "0"
        ],
        [
         "11",
         "34789",
         "21597",
         "TCP",
         "398",
         "EST",
         "165816.79355859893",
         "2026-01-12 18:11:23",
         "0"
        ],
        [
         "12",
         "54252",
         "32960",
         "TCP",
         "272",
         "EST",
         "298082.5055326456",
         "2026-01-12 18:12:09",
         "0"
        ],
        [
         "13",
         "15414",
         "13307",
         "TCP",
         "171",
         "EST",
         "436230.0599704486",
         "2026-01-12 18:13:15",
         "0"
        ],
        [
         "14",
         "39891",
         "46183",
         "UDP",
         "116",
         "EST",
         "24744.013080510103",
         "2026-01-12 18:14:36",
         "0"
        ],
        [
         "15",
         "22963",
         "8588",
         "TCP",
         "329",
         "EST",
         "193349.74691516798",
         "2026-01-12 18:15:25",
         "0"
        ],
        [
         "16",
         "28331",
         "56327",
         "TCP",
         "74",
         "EST",
         "79962.1301658161",
         "2026-01-12 18:16:46",
         "0"
        ],
        [
         "17",
         "31852",
         "31360",
         "UDP",
         "256",
         "EST",
         "347981.7711152029",
         "2026-01-12 18:17:51",
         "0"
        ],
        [
         "18",
         "29537",
         "21499",
         "UDP",
         "81",
         "EST",
         "53756.555655136304",
         "2026-01-12 18:18:32",
         "0"
        ],
        [
         "19",
         "54228",
         "4663",
         "UDP",
         "268",
         "EST",
         "332739.07153154205",
         "2026-01-12 18:19:45",
         "0"
        ],
        [
         "20",
         "55479",
         "37095",
         "TCP",
         "128",
         "EST",
         "143804.25452815575",
         "2026-01-12 18:20:18",
         "0"
        ],
        [
         "21",
         "25526",
         "41834",
         "UDP",
         "326",
         "EST",
         "100259.49005487512",
         "2026-01-12 18:21:24",
         "0"
        ],
        [
         "22",
         "31087",
         "27198",
         "TCP",
         "235",
         "EST",
         "468239.9263546677",
         "2026-01-12 18:22:42",
         "0"
        ],
        [
         "23",
         "23510",
         "20720",
         "UDP",
         "41",
         "EST",
         "10243.763796231979",
         "2026-01-12 18:23:23",
         "0"
        ],
        [
         "24",
         "47301",
         "24666",
         "TCP",
         "181",
         "EST",
         "219450.85867289492",
         "2026-01-12 18:24:35",
         "0"
        ],
        [
         "25",
         "39282",
         "43240",
         "UDP",
         "157",
         "EST",
         "11791.869238435096",
         "2026-01-12 18:25:11",
         "0"
        ],
        [
         "26",
         "58740",
         "25033",
         "TCP",
         "59",
         "EST",
         "242312.93100406017",
         "2026-01-12 18:26:35",
         "0"
        ],
        [
         "27",
         "32716",
         "59625",
         "TCP",
         "345",
         "EST",
         "251022.6415194147",
         "2026-01-12 18:27:51",
         "0"
        ],
        [
         "28",
         "39408",
         "12642",
         "UDP",
         "249",
         "EST",
         "161509.57322597876",
         "2026-01-12 18:28:52",
         "0"
        ],
        [
         "29",
         "16982",
         "22",
         "UDP",
         "445",
         "EST",
         "66948.72698498682",
         "2026-01-12 18:29:43",
         "2"
        ],
        [
         "30",
         "36040",
         "30029",
         "TCP",
         "24",
         "EST",
         "188817.38132950317",
         "2026-01-12 18:30:44",
         "0"
        ],
        [
         "31",
         "18256",
         "45495",
         "UDP",
         "80",
         "EST",
         "336459.2070263504",
         "2026-01-12 18:31:33",
         "0"
        ],
        [
         "32",
         "11772",
         "54647",
         "TCP",
         "134",
         "EST",
         "391415.5085135851",
         "2026-01-12 18:32:35",
         "0"
        ],
        [
         "33",
         "63809",
         "15652",
         "UDP",
         "213",
         "EST",
         "265844.550591683",
         "2026-01-12 18:33:08",
         "0"
        ],
        [
         "34",
         "11538",
         "8537",
         "UDP",
         "388",
         "EST",
         "295327.36282543803",
         "2026-01-12 18:34:26",
         "0"
        ],
        [
         "35",
         "23762",
         "51864",
         "TCP",
         "348",
         "EST",
         "101107.56919120169",
         "2026-01-12 18:35:27",
         "0"
        ],
        [
         "36",
         "9719",
         "56748",
         "UDP",
         "166",
         "EST",
         "144377.83628059708",
         "2026-01-12 18:36:57",
         "0"
        ],
        [
         "37",
         "9094",
         "45713",
         "UDP",
         "348",
         "EST",
         "81785.90941612684",
         "2026-01-12 18:37:25",
         "0"
        ],
        [
         "38",
         "28789",
         "6274",
         "TCP",
         "337",
         "EST",
         "125398.37965230105",
         "2026-01-12 18:38:32",
         "0"
        ],
        [
         "39",
         "42686",
         "6285",
         "TCP",
         "398",
         "EST",
         "113218.50333254035",
         "2026-01-12 18:39:31",
         "0"
        ],
        [
         "40",
         "53801",
         "59807",
         "UDP",
         "71",
         "EST",
         "260204.94440922755",
         "2026-01-12 18:40:38",
         "0"
        ],
        [
         "41",
         "31785",
         "25693",
         "TCP",
         "214",
         "EST",
         "281781.68913957395",
         "2026-01-12 18:41:44",
         "0"
        ],
        [
         "42",
         "17722",
         "8818",
         "UDP",
         "65",
         "EST",
         "472528.76298993075",
         "2026-01-12 18:42:13",
         "0"
        ],
        [
         "43",
         "16147",
         "28956",
         "UDP",
         "221",
         "EST",
         "98589.75290366",
         "2026-01-12 18:43:31",
         "0"
        ],
        [
         "44",
         "36168",
         "26556",
         "TCP",
         "308",
         "EST",
         "321196.17937058647",
         "2026-01-12 18:44:49",
         "0"
        ],
        [
         "45",
         "26640",
         "20379",
         "TCP",
         "286",
         "EST",
         "408812.3752247739",
         "2026-01-12 18:45:27",
         "0"
        ],
        [
         "46",
         "38170",
         "50831",
         "TCP",
         "185",
         "EST",
         "280560.4904277432",
         "2026-01-12 18:46:16",
         "0"
        ],
        [
         "47",
         "12206",
         "41183",
         "TCP",
         "207",
         "EST",
         "128246.82259803677",
         "2026-01-12 18:47:39",
         "0"
        ],
        [
         "48",
         "25857",
         "17128",
         "TCP",
         "99",
         "EST",
         "132012.5647799801",
         "2026-01-12 18:48:49",
         "0"
        ],
        [
         "49",
         "34366",
         "49615",
         "TCP",
         "242",
         "RST",
         "89.38315757138867",
         "2026-01-12 18:49:03",
         "3"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 2000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>protocol</th>\n",
       "      <th>packet_count</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>bytes_transferred</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48364</td>\n",
       "      <td>35671</td>\n",
       "      <td>TCP</td>\n",
       "      <td>218</td>\n",
       "      <td>EST</td>\n",
       "      <td>491361.431556</td>\n",
       "      <td>2026-01-12 18:00:32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18818</td>\n",
       "      <td>62148</td>\n",
       "      <td>TCP</td>\n",
       "      <td>373</td>\n",
       "      <td>EST</td>\n",
       "      <td>430263.657678</td>\n",
       "      <td>2026-01-12 18:01:31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20905</td>\n",
       "      <td>32564</td>\n",
       "      <td>TCP</td>\n",
       "      <td>31</td>\n",
       "      <td>EST</td>\n",
       "      <td>344261.424094</td>\n",
       "      <td>2026-01-12 18:02:21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21780</td>\n",
       "      <td>46160</td>\n",
       "      <td>UDP</td>\n",
       "      <td>368</td>\n",
       "      <td>EST</td>\n",
       "      <td>469436.194252</td>\n",
       "      <td>2026-01-12 18:03:40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41186</td>\n",
       "      <td>36487</td>\n",
       "      <td>TCP</td>\n",
       "      <td>47</td>\n",
       "      <td>EST</td>\n",
       "      <td>361433.272994</td>\n",
       "      <td>2026-01-12 18:04:45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>20300</td>\n",
       "      <td>27940</td>\n",
       "      <td>UDP</td>\n",
       "      <td>245</td>\n",
       "      <td>EST</td>\n",
       "      <td>193472.639668</td>\n",
       "      <td>2026-01-14 03:15:28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>32947</td>\n",
       "      <td>61366</td>\n",
       "      <td>TCP</td>\n",
       "      <td>284</td>\n",
       "      <td>EST</td>\n",
       "      <td>451876.092545</td>\n",
       "      <td>2026-01-14 03:16:19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>6558</td>\n",
       "      <td>1846</td>\n",
       "      <td>TCP</td>\n",
       "      <td>375</td>\n",
       "      <td>EST</td>\n",
       "      <td>120254.307290</td>\n",
       "      <td>2026-01-14 03:17:57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>27493</td>\n",
       "      <td>46711</td>\n",
       "      <td>UDP</td>\n",
       "      <td>107</td>\n",
       "      <td>EST</td>\n",
       "      <td>104050.069300</td>\n",
       "      <td>2026-01-14 03:18:49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>37098</td>\n",
       "      <td>16767</td>\n",
       "      <td>TCP</td>\n",
       "      <td>27</td>\n",
       "      <td>EST</td>\n",
       "      <td>484940.571835</td>\n",
       "      <td>2026-01-14 03:19:42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      src_port  dst_port protocol  packet_count conn_state  bytes_transferred  \\\n",
       "0        48364     35671      TCP           218        EST      491361.431556   \n",
       "1        18818     62148      TCP           373        EST      430263.657678   \n",
       "2        20905     32564      TCP            31        EST      344261.424094   \n",
       "3        21780     46160      UDP           368        EST      469436.194252   \n",
       "4        41186     36487      TCP            47        EST      361433.272994   \n",
       "...        ...       ...      ...           ...        ...                ...   \n",
       "1995     20300     27940      UDP           245        EST      193472.639668   \n",
       "1996     32947     61366      TCP           284        EST      451876.092545   \n",
       "1997      6558      1846      TCP           375        EST      120254.307290   \n",
       "1998     27493     46711      UDP           107        EST      104050.069300   \n",
       "1999     37098     16767      TCP            27        EST      484940.571835   \n",
       "\n",
       "               timestamp  attack  \n",
       "0    2026-01-12 18:00:32       0  \n",
       "1    2026-01-12 18:01:31       0  \n",
       "2    2026-01-12 18:02:21       0  \n",
       "3    2026-01-12 18:03:40       0  \n",
       "4    2026-01-12 18:04:45       0  \n",
       "...                  ...     ...  \n",
       "1995 2026-01-14 03:15:28       0  \n",
       "1996 2026-01-14 03:16:19       0  \n",
       "1997 2026-01-14 03:17:57       0  \n",
       "1998 2026-01-14 03:18:49       0  \n",
       "1999 2026-01-14 03:19:42       0  \n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"out/train.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fd28e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "src_port",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dst_port",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "protocol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "packet_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "conn_state",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bytes_transferred",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "timestamp",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "attack",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "49f973f1-e662-433d-98bc-4f06ac29d7af",
       "rows": [
        [
         "0",
         "48364",
         "35671",
         "TCP",
         "218",
         "EST",
         "491361.4315560715",
         "2026-01-12 18:00:32",
         "0"
        ],
        [
         "1",
         "18818",
         "62148",
         "TCP",
         "373",
         "EST",
         "430263.6576777548",
         "2026-01-12 18:01:31",
         "0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>protocol</th>\n",
       "      <th>packet_count</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>bytes_transferred</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48364</td>\n",
       "      <td>35671</td>\n",
       "      <td>TCP</td>\n",
       "      <td>218</td>\n",
       "      <td>EST</td>\n",
       "      <td>491361.431556</td>\n",
       "      <td>2026-01-12 18:00:32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18818</td>\n",
       "      <td>62148</td>\n",
       "      <td>TCP</td>\n",
       "      <td>373</td>\n",
       "      <td>EST</td>\n",
       "      <td>430263.657678</td>\n",
       "      <td>2026-01-12 18:01:31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   src_port  dst_port protocol  packet_count conn_state  bytes_transferred  \\\n",
       "0     48364     35671      TCP           218        EST      491361.431556   \n",
       "1     18818     62148      TCP           373        EST      430263.657678   \n",
       "\n",
       "            timestamp  attack  \n",
       "0 2026-01-12 18:00:32       0  \n",
       "1 2026-01-12 18:01:31       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5b33a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-platform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
